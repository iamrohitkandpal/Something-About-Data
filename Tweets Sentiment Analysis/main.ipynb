{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3cb03-ea69-4d75-b3ed-ff9aedd7fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        'streamlit',\n",
    "        'pandas',\n",
    "        'numpy',\n",
    "        'plotly',\n",
    "        'textblob',\n",
    "        'vaderSentiment',\n",
    "        'wordcloud',\n",
    "        'matplotlib',\n",
    "        'seaborn',\n",
    "        'tweepy',\n",
    "        'nltk',\n",
    "        'python-dotenv'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "            print(f\"‚úÖ {package} installed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to install {package}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Unexpected error installing {package}: {e}\") \n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a065f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "class TwitterClient:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è python-dotenv not installed. Install it with: pip install python-dotenv\")\n",
    "        \n",
    "        self.bearer_token = os.getenv('TWITTER_BEARER_TOKEN')\n",
    "        self.api_key = os.getenv('TWITTER_API_KEY')\n",
    "        self.api_secret = os.getenv('TWITTER_API_SECRET')\n",
    "        self.access_token = os.getenv('TWITTER_ACCESS_TOKEN')\n",
    "        self.access_token_secret = os.getenv('TWITTER_ACCESS_TOKEN_SECRET')\n",
    "        \n",
    "        if not self.bearer_token:\n",
    "            print(\"Twitter API credentials not found. Using simulated data.\")\n",
    "            self.client = None\n",
    "        else:\n",
    "            try:\n",
    "                self.client = tweepy.Client(\n",
    "                    bearer_token = self.bearer_token,\n",
    "                    consumer_key = self.api_key,\n",
    "                    consumer_secret = self.api_secret,\n",
    "                    access_token = self.access_token,\n",
    "                    access_token_secret = self.access_token_secret,\n",
    "                    wait_on_rate_limit=True\n",
    "                )\n",
    "                print(\"‚úÖ Twitter API client initialized successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error initialized Twitter client: {e}\")\n",
    "                self.client = None\n",
    "                \n",
    "    def search_tweets(self, query: str, max_results: int = 10) -> List[Dict]:\n",
    "        if not self.client:\n",
    "            return self._get_simulated_tweets(max_results)\n",
    "        \n",
    "        try:\n",
    "            tweets = self.client.search_recent_tweets(\n",
    "                query=query,\n",
    "                max_results=max_results,\n",
    "                tweet_fields=['created_at', 'author_id', 'public_metrics', 'context_annotations']  \n",
    "            )\n",
    "            \n",
    "            if not tweets.data:\n",
    "                return []\n",
    "            \n",
    "            tweet_list = []\n",
    "            for tweet in tweets.data:\n",
    "                tweet_data = {\n",
    "                    'text': tweet.text,\n",
    "                    'timestamp': tweet.created_at,\n",
    "                    'user': f\"user_{tweet.author_id}\",\n",
    "                    'likes': tweet.public_metrics['like_count'] if tweet.public_metrics else 0,\n",
    "                    'retweets': tweet.public_metrics['retweet_count'] if tweet.public_metrics else 0,\n",
    "                    'tweet_id': tweet.id\n",
    "                }\n",
    "                tweet_list.append(tweet_data)\n",
    "                \n",
    "            return tweet_list\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching tweets: {e}\")\n",
    "            return self._get_simulated_tweets(max_results)\n",
    "        \n",
    "    def _get_simulated_tweets(self, count: int) -> List[Dict]:\n",
    "        from datetime import datetime, timedelta\n",
    "        import random\n",
    "        \n",
    "        sample_tweets = [\n",
    "            \"Just discovered this amazing new coffee shop! ‚òï #coffee #love\",\n",
    "            \"Traffic is terrible today! üò§ #frustrated #commute\",\n",
    "            \"Beautiful sunset tonight üåÖ #nature #peaceful\",\n",
    "            \"My flight got delayed again... üòû #travel #delays\",\n",
    "            \"Excited for the weekend! üéâ #happy #weekend\",\n",
    "            \"This movie is absolutely incredible! Must watch üçø #movies\",\n",
    "            \"Worst customer service ever! Very disappointed üò† #complaint\",\n",
    "            \"Learning Python is so rewarding! üíª #coding #tech\",\n",
    "            \"Rain ruined my picnic plans ‚òî #weather #sad\",\n",
    "            \"Just finished a great workout! üí™ #fitness #health\"\n",
    "        ]\n",
    "        \n",
    "        tweets = []\n",
    "        for _ in range(count):\n",
    "            tweet = {\n",
    "                'text': random.choice(sample_tweets),\n",
    "                'timestamp': datetime.now() - timedelta(seconds=random.randint(0, 3600)),\n",
    "                'user': f\"user_{random.randint(1000, 9999)}\",\n",
    "                'likes': random.randint(0, 100),\n",
    "                'retweets': random.randint(0, 50),\n",
    "                'tweet_id': f\"sim_{random.randint(100000, 999999)}\"\n",
    "            }\n",
    "            tweets.append(tweet)\n",
    "        \n",
    "        return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b6b43-fbef-4f1a-8fdd-490fda39c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import asyncio\n",
    "import threading\n",
    "\n",
    "print(\"‚úÖ Libraries Imported Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a75924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSentimentAnalyzer:\n",
    "    def __init__(self) -> None:\n",
    "        from textblob import TextBlob\n",
    "        from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "        import re\n",
    "        \n",
    "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
    "        self._download_nltk_data()\n",
    "        \n",
    "    def _download_nltk_data(self):\n",
    "        import nltk\n",
    "        try:\n",
    "            for corpus in ['punkt', 'brown', 'vader_lexicon']:\n",
    "                try:\n",
    "                    nltk.download(corpus, quiet=True)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Could not download NLTK corpus '{corpus}': {e}\")\n",
    "            print(\"‚úÖ NLTK data downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not download NLTK data: {e}\")\n",
    "            print(\"Sentiment analysis may not work properly\")\n",
    "        \n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        import re\n",
    "        \n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text.strip()\n",
    "        \n",
    "    def analyze_sentiment(self, text):\n",
    "        from textblob import TextBlob\n",
    "        \n",
    "        clean_text = self.clean_text(text)\n",
    "        \n",
    "        blob = TextBlob(clean_text)\n",
    "        textblob_polarity = blob.sentiment.polarity\n",
    "        \n",
    "        vader_scores = self.vader_analyzer.polarity_scores(clean_text)\n",
    "        vader_compound = vader_scores['compound']\n",
    "        \n",
    "        if textblob_polarity > 0.1 and vader_compound > 0.05:\n",
    "            sentiment = 'Positive'\n",
    "            confidence = (abs(textblob_polarity) + abs(vader_compound)) / 2\n",
    "        elif textblob_polarity < -0.1 and vader_compound < -0.05:\n",
    "            sentiment = 'Negative'\n",
    "            confidence = (abs(textblob_polarity) + abs(vader_compound)) / 2\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "            confidence = 1 - abs(textblob_polarity - vader_compound)\n",
    "            \n",
    "        return {\n",
    "            'sentiment': sentiment,\n",
    "            'confidence': min(confidence, 1.0),\n",
    "            'textblob_polarity': textblob_polarity,\n",
    "            'vader_compound': vader_compound\n",
    "        }\n",
    "        \n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"Real-Time Twitter Sentiment Analysis\",\n",
    "        page_icon=\"üê¶\",\n",
    "        layout=\"wide\",\n",
    "        initial_sidebar_state=\"expanded\"\n",
    "    )\n",
    "    \n",
    "    # Custom CSS\n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .metric-card {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 1rem;\n",
    "        border-radius: 0.5rem;\n",
    "        margin: 0.5rem 0;\n",
    "    }\n",
    "    .positive-sentiment {\n",
    "        color: #28a745;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    .negative-sentiment {\n",
    "        color: #dc3545;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    .neutral-sentiment {\n",
    "        color: #6c757d;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    st.title(\"ü•π Real-Time Twitter Sentiment Analysis Dashboard\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    if 'twitter_client' not in st.session_state:\n",
    "        st.session_state.twitter_client = TwitterClient()\n",
    "    if 'sentiment_analyzer' not in st.session_state:\n",
    "        st.session_state.sentiment_analyzer = EnhancedSentimentAnalyzer()\n",
    "    if 'tweets_data' not in st.session_state:\n",
    "        st.session_state.tweets_data = []\n",
    "    if 'search_query' not in st.session_state:\n",
    "        st.session_state.search_query = \"python OR javascript OR coding\"\n",
    "        \n",
    "    st.sidebar.header(\"üîß Controls\")\n",
    "    \n",
    "    # Search configuration\n",
    "    st.sidebar.subheader(\"Search Configuration\")\n",
    "    search_query = st.sidebar.text_input(\n",
    "        \"Search Query:\", \n",
    "        value=st.session_state.search_query,\n",
    "        help=\"Enter keywords to search for tweets. Use OR, AND for complex queries.\"\n",
    "    )\n",
    "    \n",
    "    if search_query != st.session_state.search_query:\n",
    "        st.session_state.search_query = search_query\n",
    "        \n",
    "    tweet_count = st.sidebar.slider(\"Tweets per fetch:\", 10, 100, 20)\n",
    "    \n",
    "    auto_refresh = st.sidebar.checkbox(\"üîÑ Auto Refresh\", value=False)\n",
    "    \n",
    "    if auto_refresh:\n",
    "        refresh_interval = st.sidebar.slider(\"Refresh Interval (seconds):\", 30, 300, 60)\n",
    "        \n",
    "        if 'last_refresh_time' not in st.session_state:\n",
    "            st.session_state.last_refresh_time = time.time()\n",
    "            \n",
    "        current_time = time.time()\n",
    "        if current_time - st.session_state.last_refresh_time >= refresh_interval:\n",
    "            with st.spinner(\"üîÑ Auto-refreshing...\"):\n",
    "                fetch_tweets(search_query, tweet_count)\n",
    "                st.session_state.last_refresh_time = current_time\n",
    "                st.rerun()\n",
    "                \n",
    "        time_since_refresh = current_time - st.session_state.last_refresh_time\n",
    "        time_until_refresh = refresh_interval - time_since_refresh\n",
    "        if time_until_refresh > 0:\n",
    "            st.sidebar.info(f\"‚è∞ Next refresh in: {int(time_until_refresh)}s\")\n",
    "    \n",
    "    if st.sidebar.button(\"üîç Fetch New Tweets\", type=\"primary\"):\n",
    "        fetch_tweets(search_query, tweet_count)\n",
    "        \n",
    "    if st.sidebar.button(\"üóëÔ∏è Clear All Data\"):\n",
    "        st.session_state.tweets_data = []\n",
    "        st.rerun()\n",
    "        \n",
    "    st.sidebar.subheader(\"üóÉÔ∏è Analyze Your Tweet\")\n",
    "    user_tweet = st.sidebar.text_area(\"Enter your text:\")\n",
    "    if st.sidebar.button(\"Analyze Text\") and user_tweet:\n",
    "        analyze_user_tweet(user_tweet)\n",
    "        \n",
    "    if not st.session_state.tweets_data:\n",
    "        st.info(\"üëÜ Click 'Fetch New Tweets' to start analyzing Twitter sentiment!\")\n",
    "        fetch_tweets(search_query, tweet_count)\n",
    "    else:\n",
    "        display_dashboard()\n",
    "            \n",
    "def fetch_tweets(query, count):\n",
    "    with st.spinner(\"üîç Fetching tweets...\"):\n",
    "        try:\n",
    "            tweets = st.session_state.twitter_client.search_tweets(query, count)\n",
    "             \n",
    "            if not tweets:\n",
    "                st.warning(\"No tweets found for the given query.\")\n",
    "                return \n",
    "            \n",
    "            if len(st.session_state.tweets_data) > 1000:\n",
    "                st.session_state.tweets_data = st.session_state.tweets_data[-500:]\n",
    "             \n",
    "            for tweet in tweets:\n",
    "                analysis = st.session_state.sentiment_analyzer.analyze_sentiment(tweet['text'])\n",
    "                 \n",
    "                tweet_data = {\n",
    "                     'text': tweet['text'],\n",
    "                     'timestamp': tweet['timestamp'],\n",
    "                     'user': tweet['user'],\n",
    "                     'likes': tweet['likes'],\n",
    "                     'retweets': tweet['retweets'],\n",
    "                     'sentiment': analysis['sentiment'],\n",
    "                     'confidence': analysis['confidence'],\n",
    "                     'textblob_polarity': analysis['textblob_polarity'],\n",
    "                     'vader_compound': analysis['vader_compound'],\n",
    "                     'tweet_id': tweet.get('tweet_id', 'unknown')\n",
    "                }\n",
    "                 \n",
    "                st.session_state.tweets_data.append(tweet_data)\n",
    "                 \n",
    "            if len(st.session_state.tweets_data) > 500:\n",
    "                st.session_state.tweets_data = st.session_state.tweets_data[-500:]\n",
    "            \n",
    "            st.success(f\"‚úÖ Fetched and analyzed {len(tweets)} tweets!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå Error fetching tweets: {str(e)}\")\n",
    "            \n",
    "def analyze_user_tweet(text):\n",
    "    analysis = st.session_state.sentiment_analyzer.analyze_sentiment(text)\n",
    "    \n",
    "    sentiment_color ={\n",
    "        'Positive': 'üü¢',\n",
    "        'Negative': 'üî¥', \n",
    "        'Neutral': 'üü°'\n",
    "    }    \n",
    "    \n",
    "    st.sidebar.success(f\"{sentiment_color[analysis['sentiment']]} Sentiment: **{analysis['sentiment']}**\")\n",
    "    st.sidebar.info(f\" Confidence: **{analysis['confidence']:.2f}**\")\n",
    "    \n",
    "    tweet_data = {\n",
    "        'text': text,\n",
    "        'timestamp': datetime.now(),\n",
    "        'user': 'You',\n",
    "        'likes': 0,\n",
    "        'retweets': 0,\n",
    "        'sentiment': analysis['sentiment'],\n",
    "        'confidence': analysis['confidence'],\n",
    "        'textblob_polarity': analysis['textblob_polarity'],\n",
    "        'vader_compound': analysis['vader_compound'],\n",
    "        'tweet_id': 'user_input'\n",
    "    }\n",
    "    \n",
    "    st.session_state.tweets_data.append(tweet_data)\n",
    "    \n",
    "def display_dashboard():\n",
    "    if not st.session_state.tweets_data:\n",
    "        st.warning(\"No tweet data available. Please fetch some tweets first.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(st.session_state.tweets_data)\n",
    "    \n",
    "    if df.empty:\n",
    "        st.warning(\"Tweet data is empty. Please try fetching tweets again.\")\n",
    "        return\n",
    "    \n",
    "    display_metrics(df)\n",
    "    display_charts(df)\n",
    "    display_recent_tweets(df)\n",
    "    \n",
    "def display_metrics(df):\n",
    "    if df.empty:\n",
    "        st.info(\"No data available for metrics display.\")\n",
    "        return \n",
    "    \n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    \n",
    "    total_tweets = len(df)\n",
    "    sentiment_counts = df['sentiment'].value_counts()\n",
    "    \n",
    "    with col1:\n",
    "        st.metric(\"üìä Total Tweets\", total_tweets)\n",
    "    \n",
    "    with col2:\n",
    "        positive_pct = (sentiment_counts.get('Positive', 0) / total_tweets) * 100\n",
    "        st.metric(\"üòä Positive\", f\"{positive_pct:.1f}%\", \n",
    "                 delta=f\"{sentiment_counts.get('Positive', 0)} tweets\")\n",
    "    \n",
    "    with col3:\n",
    "        negative_pct = (sentiment_counts.get('Negative', 0) / total_tweets) * 100\n",
    "        st.metric(\"üòû Negative\", f\"{negative_pct:.1f}%\",\n",
    "                 delta=f\"{sentiment_counts.get('Negative', 0)} tweets\")\n",
    "    \n",
    "    with col4:\n",
    "        avg_confidence = df['confidence'].mean()\n",
    "        st.metric(\"üéØ Avg Confidence\", f\"{avg_confidence:.2f}\")\n",
    "        \n",
    "def display_charts(df):\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"üìà Sentiment Distribution\")\n",
    "        sentiment_counts = df['sentiment'].value_counts()\n",
    "        \n",
    "        colors = {'Positive': '#28a745', 'Negative': '#dc3545', 'Neutral': '#6c757d'}\n",
    "        fig = px.pie(\n",
    "            values = sentiment_counts.values,\n",
    "            names = sentiment_counts.index,\n",
    "            color = sentiment_counts.index,\n",
    "            color_discrete_map = colors,\n",
    "            title = \"Sentiment Breakdown\"\n",
    "        )\n",
    "        fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "    with col2:\n",
    "        st.subheader(\"‚åõ Sentiment Timeline\")\n",
    "        df_sorted = df.sort_values('timestamp').tail(50)\n",
    "        \n",
    "        fig = px.scatter(\n",
    "            df_sorted,\n",
    "            x='timestamp',\n",
    "            y='confidence',\n",
    "            color='sentiment',\n",
    "            color_discrete_map=colors,\n",
    "            title='Sentiment Confidence Over Time',\n",
    "            hover_data=['text']\n",
    "        )\n",
    "        fig.update_layout(xaxis_title=\"Time\", yaxis_title=\"Confidence Score\")\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "    st.subheader(\"üí≠ Word Cloud\")\n",
    "    create_wordcloud(df)\n",
    "    \n",
    "    st.subheader(\"üìä Confidence Score Distribution\")\n",
    "    fig = px.violin(\n",
    "        df,\n",
    "        x = 'sentiment',\n",
    "        y = 'confidence',\n",
    "        color = 'sentiment',\n",
    "        color_discrete_map = colors,\n",
    "        title = 'Confidence Score Distribution by Sentiment'\n",
    "    )\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "def create_wordcloud(df):\n",
    "    try:  \n",
    "        if df.empty or 'text' not in df.columns:\n",
    "            st.info(\"No text data available for word cloud\")\n",
    "            return\n",
    "        \n",
    "        all_text = ' '.join(df['text'].astype(str).tolist())\n",
    "        \n",
    "        import re\n",
    "        all_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', all_text)\n",
    "        all_text = re.sub(r'@\\w+|#\\w+', '', all_text)\n",
    "        all_text = ' '.join(all_text.split())\n",
    "        \n",
    "        if len(all_text.strip()) < 10:\n",
    "            st.info(\"Not enough text data for meaningful word cloud\")\n",
    "            return\n",
    "        \n",
    "        \n",
    "        wordcloud = WordCloud(\n",
    "            width=800,\n",
    "            height=400,\n",
    "            background_color='white',\n",
    "            colormap='viridis',\n",
    "            max_words=100,\n",
    "            relative_scaling=0.5,\n",
    "            collocations=False\n",
    "        ).generate(all_text)\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        st.pyplot(fig)\n",
    "        plt.close(fig)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error creating word cloud: {e}\")\n",
    "        st.info(\"Skipping word cloud due to error\")\n",
    "\n",
    "def display_recent_tweets(df):\n",
    "    \"\"\"Display recent tweets in a table\"\"\"\n",
    "    st.subheader(\"üê¶ Recent Tweets\")\n",
    "    \n",
    "    df_display = df.sort_values('timestamp', ascending=False).head(20).copy()\n",
    "    \n",
    "    df_display['Time'] = pd.to_datetime(df_display['timestamp']).dt.strftime('%H:%M:%S')\n",
    "    df_display['Tweet'] = df_display['text'].str[:100] + '...'\n",
    "    df_display['Engagement'] = df_display['likes'] + df_display['retweets']\n",
    "    \n",
    "    display_cols = ['Time', 'Tweet', 'sentiment', 'confidence', 'Engagement']\n",
    "    df_show = df_display[display_cols].copy()\n",
    "    df_show['confidence'] = df_show['confidence'].round(3)\n",
    "    \n",
    "    def style_sentiment(val):\n",
    "        if val == 'Positive':\n",
    "            return 'background-color: #d4edda; color: #155724'\n",
    "        elif val == 'Negative':\n",
    "            return 'background-color: #f8d7da; color: #721c24'\n",
    "        else:\n",
    "            return 'background-color: #e2e3e5; color: #383d41'\n",
    "        \n",
    "    styled_df = df_show.style.map(style_sentiment, subset=['sentiment'])\n",
    "    st.dataframe(styled_df, use_container_width=True, height=400)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dashboard():\n",
    "    \"\"\"Run the Streamlit dashboard\"\"\"\n",
    "    print(\"üöÄ Starting Real-Time Sentiment Analysis Dashboard...\")\n",
    "    print(\"üìä The dashboard will open in your browser\")\n",
    "    print(\"---\")\n",
    "    \n",
    "    main()\n",
    "\n",
    "run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
